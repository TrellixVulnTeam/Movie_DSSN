        imdbreviewdf = pd.DataFrame({'review': [], 'sentiment': []})
        for i in range(1, 11):
            reviewurl = 'https://www.imdb.com' + imdbtitletag + 'reviews?sort=helpfulnessScore&dir=desc&ratingFilter=' + str(i)
            reviewr = requests.get(url=reviewurl)
            review_soup = BeautifulSoup(reviewr.text, 'html.parser')
            review_tags = review_soup.find_all('div', attrs={'class': 'text show-more__control'})
            for j in review_tags:
                if i <= 5:
                    tem = 'negative'
                else:
                    tem = 'positive'
                imdbreviewdf.loc[len(imdbreviewdf.index)] = [j.get_text(), tem]

        imdbreviewdf['review'] = imdbreviewdf['review']
        stopword_list = nltk.corpus.stopwords.words('english')
        tokenizer = ToktokTokenizer()
        tokens = tokenizer.tokenize(imdbreviewdf['review'])
        tokens = [token.strip() for token in tokens]
        is_lower_case=False
        if is_lower_case:
            filtered_tokens = [token for token in tokens if token not in stopword_list]
        else:
            filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]
        filtered_text = ' '.join(filtered_tokens)
        imdbreviewdf['review']= filtered_text
        lb = LabelBinarizer()
        imdbreviewdf['sentiment'] = lb.fit_transform(imdbreviewdf['sentiment'])
        X_train, X_test, y_train, y_test = train_test_split(imdbreviewdf['review'], imdbreviewdf['sentiment'],
                                                            test_size=0.33, random_state=42)
        cv = CountVectorizer(min_df=0, max_df=1, binary=False, ngram_range=(1, 3))
        cv_train_reviews = cv.fit_transform(X_train)
        cv_test_reviews = cv.transform(X_test)
        train_sentiments = y_train
        test_sentiments = y_test
        lr = LogisticRegression(penalty='l2', max_iter=500, C=1, random_state=42)
        lr_bow = lr.fit(cv_train_reviews, train_sentiments)
        lr_bow_predict = lr.predict(cv_test_reviews)
        lr_bow_score = accuracy_score(test_sentiments, lr_bow_predict)
        lr_bow_report = classification_report(test_sentiments, lr_bow_predict, target_names=['Positive', 'Negative'])
        lr_bow_report = lr_bow_report.splitlines()
        res = []
        res.append([''] + lr_bow_report[0].split())
        for row in lr_bow_report[2:-2]:
            res.append(row.split())
        lr = lr_bow_report[-1].split()
        res.append([' '.join(lr[:3])] + lr[3:])
        ans= np.array(res)
        print(ans)












            stopword_list = nltk.corpus.stopwords.words('english')
            tokenizer = nltk.tokenize.toktok.ToktokTokenizer()
            tokens = tokenizer.tokenize(imdbreviewdf['review'])
            tokens = [token.strip() for token in tokens]
            is_lower_case = False
            if is_lower_case:
                filtered_tokens = [token for token in tokens if token not in stopword_list]
            else:
                filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]
            filtered_text = ' '.join(filtered_tokens)
            imdbreviewdf['review'] = filtered_text








            AlldfDemo.loc[len(AlldfDemo.index)] = [[listAll[0][i], listAll[0][i + 1]],
                                               [listAll[0][i + 2], listAll[0][i + 3]],
                                               [listAll[0][i + 4], listAll[0][i + 5]],
                                               [listAll[0][i + 6], listAll[0][i + 7]],
                                               [listAll[0][i + 8], listAll[0][i + 9]]]












        x3 = Alldf['rating']
        y3 = Alldf['percentage']
        plt.scatter(x3, y3)
        fig3 = plt.gcf()
        buf3 = io.BytesIO()
        fig3.savefig(buf3, format='png')
        buf3.seek(0)
        string3 = base64.b64encode(buf3.read())
        uri3 = urllib.parse.quote(string3)

        x4 = Alldf['rating']
        y4 = Alldf['percentage']
        plt.scatter(x4, y4)
        fig4 = plt.gcf()
        buf4 = io.BytesIO()
        fig4.savefig(buf4, format='png')
        buf4.seek(0)
        string4 = base64.b64encode(buf4.read())
        uri4 = urllib.parse.quote(string4)

        x5 = Alldf['rating']
        y5 = Alldf['percentage']
        plt.scatter(x5, y5)
        fig5 = plt.gcf()
        buf5 = io.BytesIO()
        fig5.savefig(buf5, format='png')
        buf5.seek(0)
        string5 = base64.b64encode(buf5.read())
        uri5 = urllib.parse.quote(string5)